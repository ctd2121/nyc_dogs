head(5)
top_colors <- as.list(as.character(top_colors$value))
dogs_top_colors <- dogs_df %>%
filter(dominant_color %in% top_colors)
# create dataframe with new level names
dogs_bot_colors <- dogs_df %>%
filter(!(dominant_color %in% top_colors))
dogs_bot_colors$dominant_color = "OTHER"
dogs_df_v2 <- rbind(dogs_top_colors, dogs_bot_colors)
dogs_df_v2$dominant_color <- factor(dogs_df_v2$dominant_color)
# convert levels to lower case
levels(dogs_df_v2$dominant_color) <- c("Black", "Blond", "Brown", "Tan", "White", "Other")
# sort levels by frequency
dogs_df_v2$dominant_color <- fct_infreq(dogs_df_v2$dominant_color)
dogs_df_v2$Group <- fct_infreq(dogs_df_v2$Group)
# put "Other" level at the end of order
dogs_df_v2$dominant_color <- factor(dogs_df_v2$dominant_color, levels(dogs_df_v2$dominant_color)[c(1,2,4,5,6,3)])
vcd::mosaic(~ Group + dominant_color,
data = dogs_df_v2,
direction = "v",
main = "Dominant Color vs. Group",
labeling= labeling_border(rot_labels = c(45,0,0,30),
just_labels = c("left",
"center",
"center",
"center")))
```
From this mosaic plot, we see that `mutts` are more highly associated with the `dominant color` `black` than they are with any other `dominant color`, while `toy` dogs are most highly associated with both `black` and `white`. The remaining six `groups` are significantly less prevalent than `mutts` and `toy` dogs in the dataset, but these remaining six groups show higher associations with particular groups than do `mutts` and `toy` dogs. Specifically, `non-sporting` dogs and `terriers` are both associated with `white`, while `working`, `hound`, and `herding` dogs are highly associated with `black`. `Sporting` dogs are not super highly associated with any single `dominant color`, but they are more highly associated with `black`, `brown`, and `blond` than they are with `white` or `tan`.
(b) Redraw with the "OTHER" category filtered out. Do the results change? How should one decide whether it's necessary or not to include an "OTHER" category?
```{r}
dogs_df_v3 <- dogs_df_v2 %>%
filter(dominant_color != "Other")
dogs_df_v3$dominant_color <- factor(dogs_df_v3$dominant_color)
vcd::mosaic(~ Group + dominant_color,
data = dogs_df_v3,
direction = "v",
main = "Dominant Color vs. Group",
labeling= labeling_border(rot_labels = c(45,0,0,30),
just_labels = c("left",
"center",
"center",
"center")))
```
This second mosaic plot actually does not change significantly from the original mosaic plot in which the `OTHER` category is included. Because the `OTHER` category does not dominate the observations in the dataset (that is, only about 20% of observations have `OTHER` as their `dominant color`), removing the color group from the mosaic plot does not noticeably affect the visualization.
It is likely that if `OTHER` constituted the majority of observations in the dataset, then removing the color group would have a much greater impact on the relative proportions of the remaining categories. To decide whether it is necessary or not to include an `OTHER` category, experimentation is the best way to go, as it all depends on the inherent nature of the dataset of interest.
### 4. Maps
Draw a spatial heat map of the percent spayed or neutered dogs by zip code. What patterns do you notice?
```{r}
#devtools::install_github("arilamstein/choroplethrZip")
library(choroplethr)
library(choroplethrZip)
zips_df <- dogs_df[c(8,11)] %>%
group_by(zip_code, spayed_or_neutered) %>%
summarise(counts = n()) %>%
spread(spayed_or_neutered, counts, fill = 0) %>%
mutate(percent = 100 * (Yes / (No + Yes))) %>%
transmute(region = as.character(zip_code), value = percent)
zips_df$zip_code <- as.character(zips_df$zip_code)
nyc_fips <- c(36005, 36047, 36061, 36081, 36085)
zip_choropleth(zips_df,
title = "Spatial Heat Map of Spayed or Neutered Dogs in NYC",
county_zoom = nyc_fips,
legend = "Percent Spayed or Neutered Dogs")
```
From this spatial heat map, it appears that Manhattan and Staten Island have relatively higher percentages of dogs that are spayed or neutered compared to those in the Bronx, Queens, and Brooklyn. The Bronx also appears to be the borough with the lowest percentages of spayed or neutered dogs. Additionally, there are some "NA" values in this heat map, as there are some counties for which there is no data in our dataset; such counties exist primarily in Queens, specifically on the eastern coast of the borough.
### 5. Time Series
(a) Use the `tidyquant` package to collect information on four tech stocks of your choosing. Create a multiple line chart of the closing prices of the four stocks on the same graph, showing each stock in a different color.
```{r}
library(tidyquant)
# get MTSI data and format
mtsi_df <- tq_get("MTSI")
mtsi_df <- data.frame(ticker = "MTSI", mtsi_df$date, mtsi_df$close)
colnames(mtsi_df) <- c('Ticker', 'date', 'close')
# get TSLA data and format
tsla_df <- tq_get("TSLA")
tsla_df <- data.frame(ticker = "TSLA", tsla_df$date, tsla_df$close)
colnames(tsla_df) <- c('Ticker', 'date', 'close')
# get YELP data and format
yelp_df <- tq_get("YELP")
yelp_df <- data.frame(ticker = "YELP", yelp_df$date, yelp_df$close)
colnames(yelp_df) <- c('Ticker', 'date', 'close')
# get FB data and format
fb_df <- tq_get("FB")
fb_df <- data.frame(ticker = "FB", fb_df$date, fb_df$close)
colnames(fb_df) <- c('Ticker', 'date', 'close')
stocks_df <- rbind(mtsi_df, tsla_df, yelp_df, fb_df)
ggplot(stocks_df, aes(x = date, y = close, color = Ticker)) +
geom_line() +
xlab('Date') +
ylab('Closing Price') +
theme(axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
plot.title = element_text(hjust = 0.5, size = 16),
legend.title = element_text(hjust = 0.5, size = 10)) +
ggtitle('Closing Prices for MTSI, TSLA, YELP, and FB')
```
(b) Transform the data so each stock begins at 100 and replot. Choose a starting date for which you have data on all of the stocks. Do you learn anything new that wasn't visible in (a)?
```{r}
transformed_mtsi <- filter(mtsi_df, date >= fb_df$date[1])
transformed_tsla <- filter(tsla_df, date >= fb_df$date[1])
transformed_yelp <- filter(yelp_df, date >= fb_df$date[1])
stocks_df_v2 <- rbind(transformed_mtsi, transformed_tsla, transformed_yelp, fb_df)
transformed_df <- stocks_df_v2 %>%
group_by('Ticker') %>%
mutate(ipo = ifelse(Ticker == 'MTSI', transformed_mtsi$close[1],
ifelse(Ticker == 'TSLA', transformed_tsla$close[1],
ifelse(Ticker == 'YELP', transformed_yelp$close[1],
fb_df$close[1])))) %>%
mutate(index = round(100*close/ipo, 2)) %>%
ungroup()
ggplot(transformed_df, aes(x = date, y = index, color = Ticker)) +
geom_line() +
xlab('Date') +
ylab('Index') +
theme(axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
plot.title = element_text(hjust = 0.5, size = 16),
legend.title = element_text(hjust = 0.5, size = 10)) +
ggtitle('Price Indices for MTSI, TSLA, YELP, and FB')
```
Since the stock prices are now indexed, the four stocks have the same baseline and it is thus easier to compare relative growths over time. For example, we see that YELP outpaces MTSI and FB between 2013 and 2015, but this trend is not very apparent in the original graph from part (a). This is because in the original graph/dataset, TSLA's stock prices are much greater than those of the other three tech stocks, so the scale causes TSLA prices to mask trends that are occuring between the other three stocks. This new graph also makes spikes and dips in stock prices more apparent, whereas the scale from the original graph results in stock price movements appearing smoother than they are in actuality. Although the graph in part (a) is able to display actual stock prices (which specific audiences may be directly interested in), this new graph displays everything in relative proportions, aiding in the display of growth trends between these stocks.
### 6. Presentation
Imagine that you have been asked to create a graph from the Dogs of NYC dataset that will be presented to a very important person (or people). The stakes are high.
(a) Who is the audience? (Mayor DeBlasio, a real estate developer, the voters, the City Council, the CEO of Purina...)
The general public is the intended audience of this graph; residents of New York City serve as a more niche audience.
(b) What is the main point you hope someone will take away from the graph?
The purpose of this Cleveland Dot Plot is to inform the public about popularities of dog `groups` within New York City over time. Specifically, the primary purpose of the graph is to display the significantly larger increase in popularity of `mutts` and `toy` dogs over time. From the graph, it is clear that the growth of these two `groups` greatly outpaces that of all other `groups`. All dog `groups` show increases in counts over time (as dogs in general become more popular as a pet), but beginning around 1996, the counts of `mutts` and `toy` dogs in NYC diverge from the counts of the other six dog `groups`.
(c) Present the graph, cleaned up to the standards of "presentation style." Pay attention to choice of graph type, if and how the data will be summarized, if and how the data will be subsetted, title, axis labels, axis breaks, axis tick mark labels, color, gridlines, and any other relevant features.
facet by borough
spayed/neutered color
```{r}
dog_groups_ts <- dogs_df_v1[c(2,4,5,12)] %>%
mutate(birth_year = substr(birth, 1, 4)) %>%
group_by(birth_year, Group) %>%
summarise(counts = n()) %>%
filter(1991 < birth_year & birth_year < 2012)
ggplot(dog_groups_ts, aes(x = counts,
y = birth_year,
color = Group)) +
geom_point() +
labs(color = 'Dog Group') +
ggtitle('NYC Dog Group Counts by Year') +
scale_x_continuous(name = 'Count') +
scale_y_discrete(name = 'Year') +
theme(axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
plot.title = element_text(hjust = 0.5, size = 16),
legend.title = element_text(hjust = 0.5, size = 10))
```
zips_df <- dogs_df[c(8,11)] %>%
group_by(zip_code, spayed_or_neutered) %>%
summarise(counts = n()) %>%
spread(spayed_or_neutered, counts, fill = 0) %>%
mutate(percent = 100 * (Yes / (No + Yes))) %>%
transmute(region = as.character(zip_code), value = percent)
library(ggplot2)
library(tidyverse)
library(dplyr)
dogs_df <- read.csv("NYCdogs.csv")
---
title: "Homework #3"
author: "Connor Daly"
date: "October 30, 2018"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
```
For questions 1-4 in this problem set, we will work with a dataset on dogs of New York City, found here: https://project.wnyc.org/dogs-of-nyc/
**Please use the "NYCdogs.csv" version found in Files/Data folder on CourseWorks, which includes a Group column.  If you already did some of the questions that didn't require the Group column, you do not have to redo them.**
Background: The dataset is dated June 26, 2012. Although the data were originally produced by the NYC Department of Mental Health and Hygiene, it no longer seems to be available on any official NYC web site. (There is a 2016 dataset on dog licenses with different variables available here: https://data.cityofnewyork.us/Health/NYC-Dog-Licensing-Dataset/nu7n-tubp). Also of note is the fact that this dataset has 81,542 observations. The same summer, the New York City Economic Development Corporation estimated that there were 600,000 dogs in New York City (source: https://blog.nycpooch.com/2012/08/28/how-many-dogs-live-in-new-york-city/) Quite a difference! How many dogs were there really in 2012?!? Might be an interesting question to pursue for a final project, but for now we'll work with what we've got.
### 1. Missing Data
(a) Create a bar chart showing percent missing by variable.
```{r}
library(ggplot2)
library(tidyverse)
library(dplyr)
dogs_df <- read.csv("NYCdogs.csv")
dogs_df <- data.frame(lapply(dogs_df, function(x) {
gsub("n/a", NA, x)
}))
missing <- colSums(is.na(dogs_df))
missing_df <- data.frame(missing) %>%
add_rownames("var")
missing_df['missing_pct'] = (missing / nrow(dogs_df))*100
ggplot(filter(missing_df, missing_pct > 0), aes(x = reorder(var, -missing_pct), y = missing_pct)) +
geom_bar(stat = "identity",
fill = "red",
color = "black",
alpha = 0.6) +
ggtitle("Missing Values by Variable (excludes variables with no missing values)") +
scale_x_discrete(name = "Variable") +
scale_y_continuous(name = "Percent Missing") +
theme(plot.title = element_text(hjust = 0.5, size = 14),
axis.title.x = element_text(size = 12),
axis.title.y = element_text(size = 12))
```
(b) Use the `extracat::visna()` to graph missing patterns. Interpret the graph.
```{r fig.height = 6}
library(extracat)
visna(dogs_df, sort = "b")
```
This graph shows that there are a total of five variables (`third_color`, `secondary_color`, `dog_name`, `dominant_color`, and `gender`) in the dataset that have some amount of missing values. Specifically, `third_color` is the most frequently missing variable and `secondary_color` is the second most frequently missing variable; `dog_name`, `dominant_color`, and `gender` have relatively small percentages of missing values relative to `third_color` and `secondary_color`.
Additionally, of all observations that have missing values, the most commonly observed pattern is a missing value for only the `third_color` variable. It is also relatively common to see observations missing values for both `third_color` and `secondary_color`. It is interesting to note that both of these described patterns are more frequently observed in the dataset than is an observation that has no missing values. There are also some observations in the dataset which are missing all five variables, but this is the most infrequently observed pattern.
(c) Do `dog_name` missing patterns appear to be associated with the *value* of `gender`, `Group` *or* `borough`?
```{r}
patterns <- dogs_df %>%
filter(is.na(dog_name)) %>%
filter(is.na(gender) == FALSE) %>%
filter(is.na(Group) == FALSE) %>%
filter(is.na(borough) == FALSE)
patterns <- patterns[c(1,2,10,12)]
format(prop.table(table(patterns$gender))/prop.table(table(dogs_df$gender)), digits = 2)
format(prop.table(table(patterns$Group))/prop.table(table(dogs_df$Group)), digits = 2)
format(prop.table(table(patterns$borough))/prop.table(table(dogs_df$borough)), digits = 2)
```
The three tables above show the proportion of respective variables in the original dataset divided by the proportion of respective variables for observations in which `dog_name` is missing. That is, a value of 1.00 indicates that there is no association between `dog_name` missing patterns and the corresponding variable of interest. From the tables above, it appears that `male` dogs are slightly more likely to have missing values for `dog_name` than are `female` dogs. Additionally, there is an association between `dog_name` missing patterns and dogs in the `non-sporting` and `toy` groups, as these dog `groups` are most likely to have missing values for `dog_name` (since `non-sporting` dogs have a value of 1.38 and `toy` dogs have a value of 1.27). Finally, dogs from `Brooklyn` and `Queens` are slightly more associated with missing values for `dog_name`, while dogs from `Staten Island` are less likely to have missing `dog_name` values (shown from its value of 0.83).
### 2. Dates
(a) Convert the `birth` column of the NYC dogs dataset to `Date` class (use "01" for the day since it's not provided). Create a frequency histogram of birthdates with a one-month binwidth.  (Hint: don't forget about base R.) What do you observe? Provide a reasonable hypothesis for the prominent pattern in the graph.
```{r}
dogs_df$birth <- as.character(dogs_df$birth)
dogs_df_v1 <- dogs_df %>%
mutate(birth = ifelse((substr(birth, 2, 2) == "-"),
paste0(substr(birth, 3, 5), "-", substr(birth, 1, 1)),
birth)) %>%
filter(nchar(birth) > 2) %>%
mutate(birth = ifelse((nchar(birth) == 5 & substr(birth, 4, 4) == "-"),
paste0(substr(birth, 1, 4), "0", substr(birth, 5, 5)),
birth)) %>%
mutate(birth = ifelse((substr(birth, 3, 3) == "-"),
paste0(substr(birth, 4, 6), "-", substr(birth, 1, 2)),
birth)) %>%
mutate(birth = paste0(birth, "-01")) %>%
mutate(birth = as.Date(birth, "%b-%y-%d"))
hist(dogs_df_v1$birth, "months", freq = TRUE,
main = "Birthdates Histogram",
xlab = "Birth Month",
format = "%b %y")
```
There are primarily two anomalies in this histogram. First, the range of possible values implies a clear error in the data; there are some observations with recorded `birth` years greater than 2065. When inspecting the dataset, it turns out there is one observation with `birth` year 2066 and one observation with `birth` year 2067, while the maximum `birth` year for all other observations is 2012. Since these `birth` dates are impossible, it makes sense to throw out these observations; our dataset has over 80 thousand observations, so excluding two observations will not alter our analysis.
Secondly, there is a strange pattern in the histogram, where the frequency spikes at seemingly constant intervals. After examining the dataset, it becomes clear that the frequency spikes occur every January. This possibly stems from the inherent nature of the data. It is possible that January served as the default `birth` month value for dogs whose exact `birth` month was unknown.
(b) Redraw the frequency histogram with impossible values removed and a more reasonable binwidth.
```{r}
dogs_df_v1 <- dogs_df_v1 %>%
filter(birth < "2018-01-01" & birth > "1994-01-01")
hist(dogs_df_v1$birth, "years", freq = TRUE,
main = "Birthdates Histogram",
xlab = "Birth Year",
format = "%Y")
```
### 3. Mosaic plots
(a) Create a mosaic plot to see if `dominant_color` depends on `Group`. Use only the top 5 dominant colors; group the rest into an "OTHER" category. The last split should be the dependent variable and it should be horizontal. Sort each variable by frequency, with the exception of "OTHER", which should be the last category for dominant color. The labeling should be clear enough to identify what's what; it doesn't have to be perfect. Do the variables appear to be associated? Briefly describe.
```{r}
library(vcd)
library(forcats)
# get the top five dominant colors
color_counts <- aggregate(data.frame(count = dogs_df$dominant_color),
list(value = dogs_df$dominant_color), length) %>%
arrange(-count)
top_colors <- color_counts %>%
head(5)
top_colors <- as.list(as.character(top_colors$value))
dogs_top_colors <- dogs_df %>%
filter(dominant_color %in% top_colors)
# create dataframe with new level names
dogs_bot_colors <- dogs_df %>%
filter(!(dominant_color %in% top_colors))
dogs_bot_colors$dominant_color = "OTHER"
dogs_df_v2 <- rbind(dogs_top_colors, dogs_bot_colors)
dogs_df_v2$dominant_color <- factor(dogs_df_v2$dominant_color)
# convert levels to lower case
levels(dogs_df_v2$dominant_color) <- c("Black", "Blond", "Brown", "Tan", "White", "Other")
# sort levels by frequency
dogs_df_v2$dominant_color <- fct_infreq(dogs_df_v2$dominant_color)
dogs_df_v2$Group <- fct_infreq(dogs_df_v2$Group)
# put "Other" level at the end of order
dogs_df_v2$dominant_color <- factor(dogs_df_v2$dominant_color, levels(dogs_df_v2$dominant_color)[c(1,2,4,5,6,3)])
vcd::mosaic(~ Group + dominant_color,
data = dogs_df_v2,
direction = "v",
main = "Dominant Color vs. Group",
labeling= labeling_border(rot_labels = c(45,0,0,30),
just_labels = c("left",
"center",
"center",
"center")))
```
From this mosaic plot, we see that `mutts` are more highly associated with the `dominant color` `black` than they are with any other `dominant color`, while `toy` dogs are most highly associated with both `black` and `white`. The remaining six `groups` are significantly less prevalent than `mutts` and `toy` dogs in the dataset, but these remaining six groups show higher associations with particular groups than do `mutts` and `toy` dogs. Specifically, `non-sporting` dogs and `terriers` are both associated with `white`, while `working`, `hound`, and `herding` dogs are highly associated with `black`. `Sporting` dogs are not super highly associated with any single `dominant color`, but they are more highly associated with `black`, `brown`, and `blond` than they are with `white` or `tan`.
(b) Redraw with the "OTHER" category filtered out. Do the results change? How should one decide whether it's necessary or not to include an "OTHER" category?
```{r}
dogs_df_v3 <- dogs_df_v2 %>%
filter(dominant_color != "Other")
dogs_df_v3$dominant_color <- factor(dogs_df_v3$dominant_color)
vcd::mosaic(~ Group + dominant_color,
data = dogs_df_v3,
direction = "v",
main = "Dominant Color vs. Group",
labeling= labeling_border(rot_labels = c(45,0,0,30),
just_labels = c("left",
"center",
"center",
"center")))
```
This second mosaic plot actually does not change significantly from the original mosaic plot in which the `OTHER` category is included. Because the `OTHER` category does not dominate the observations in the dataset (that is, only about 20% of observations have `OTHER` as their `dominant color`), removing the color group from the mosaic plot does not noticeably affect the visualization.
It is likely that if `OTHER` constituted the majority of observations in the dataset, then removing the color group would have a much greater impact on the relative proportions of the remaining categories. To decide whether it is necessary or not to include an `OTHER` category, experimentation is the best way to go, as it all depends on the inherent nature of the dataset of interest.
### 4. Maps
Draw a spatial heat map of the percent spayed or neutered dogs by zip code. What patterns do you notice?
```{r}
#devtools::install_github("arilamstein/choroplethrZip")
library(choroplethr)
library(choroplethrZip)
zips_df <- dogs_df[c(8,11)] %>%
group_by(zip_code, spayed_or_neutered) %>%
summarise(counts = n()) %>%
spread(spayed_or_neutered, counts, fill = 0) %>%
mutate(percent = 100 * (Yes / (No + Yes))) %>%
transmute(region = as.character(zip_code), value = percent)
zips_df$zip_code <- as.character(zips_df$zip_code)
nyc_fips <- c(36005, 36047, 36061, 36081, 36085)
zip_choropleth(zips_df,
title = "Spatial Heat Map of Spayed or Neutered Dogs in NYC",
county_zoom = nyc_fips,
legend = "Percent Spayed or Neutered Dogs")
```
From this spatial heat map, it appears that Manhattan and Staten Island have relatively higher percentages of dogs that are spayed or neutered compared to those in the Bronx, Queens, and Brooklyn. The Bronx also appears to be the borough with the lowest percentages of spayed or neutered dogs. Additionally, there are some "NA" values in this heat map, as there are some counties for which there is no data in our dataset; such counties exist primarily in Queens, specifically on the eastern coast of the borough.
### 5. Time Series
(a) Use the `tidyquant` package to collect information on four tech stocks of your choosing. Create a multiple line chart of the closing prices of the four stocks on the same graph, showing each stock in a different color.
```{r}
library(tidyquant)
# get MTSI data and format
mtsi_df <- tq_get("MTSI")
mtsi_df <- data.frame(ticker = "MTSI", mtsi_df$date, mtsi_df$close)
colnames(mtsi_df) <- c('Ticker', 'date', 'close')
# get TSLA data and format
tsla_df <- tq_get("TSLA")
tsla_df <- data.frame(ticker = "TSLA", tsla_df$date, tsla_df$close)
colnames(tsla_df) <- c('Ticker', 'date', 'close')
# get YELP data and format
yelp_df <- tq_get("YELP")
yelp_df <- data.frame(ticker = "YELP", yelp_df$date, yelp_df$close)
colnames(yelp_df) <- c('Ticker', 'date', 'close')
# get FB data and format
fb_df <- tq_get("FB")
fb_df <- data.frame(ticker = "FB", fb_df$date, fb_df$close)
colnames(fb_df) <- c('Ticker', 'date', 'close')
stocks_df <- rbind(mtsi_df, tsla_df, yelp_df, fb_df)
ggplot(stocks_df, aes(x = date, y = close, color = Ticker)) +
geom_line() +
xlab('Date') +
ylab('Closing Price') +
theme(axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
plot.title = element_text(hjust = 0.5, size = 16),
legend.title = element_text(hjust = 0.5, size = 10)) +
ggtitle('Closing Prices for MTSI, TSLA, YELP, and FB')
```
(b) Transform the data so each stock begins at 100 and replot. Choose a starting date for which you have data on all of the stocks. Do you learn anything new that wasn't visible in (a)?
```{r}
transformed_mtsi <- filter(mtsi_df, date >= fb_df$date[1])
transformed_tsla <- filter(tsla_df, date >= fb_df$date[1])
transformed_yelp <- filter(yelp_df, date >= fb_df$date[1])
stocks_df_v2 <- rbind(transformed_mtsi, transformed_tsla, transformed_yelp, fb_df)
transformed_df <- stocks_df_v2 %>%
group_by('Ticker') %>%
mutate(ipo = ifelse(Ticker == 'MTSI', transformed_mtsi$close[1],
ifelse(Ticker == 'TSLA', transformed_tsla$close[1],
ifelse(Ticker == 'YELP', transformed_yelp$close[1],
fb_df$close[1])))) %>%
mutate(index = round(100*close/ipo, 2)) %>%
ungroup()
ggplot(transformed_df, aes(x = date, y = index, color = Ticker)) +
geom_line() +
xlab('Date') +
ylab('Index') +
theme(axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
plot.title = element_text(hjust = 0.5, size = 16),
legend.title = element_text(hjust = 0.5, size = 10)) +
ggtitle('Price Indices for MTSI, TSLA, YELP, and FB')
```
Since the stock prices are now indexed, the four stocks have the same baseline and it is thus easier to compare relative growths over time. For example, we see that YELP outpaces MTSI and FB between 2013 and 2015, but this trend is not very apparent in the original graph from part (a). This is because in the original graph/dataset, TSLA's stock prices are much greater than those of the other three tech stocks, so the scale causes TSLA prices to mask trends that are occuring between the other three stocks. This new graph also makes spikes and dips in stock prices more apparent, whereas the scale from the original graph results in stock price movements appearing smoother than they are in actuality. Although the graph in part (a) is able to display actual stock prices (which specific audiences may be directly interested in), this new graph displays everything in relative proportions, aiding in the display of growth trends between these stocks.
### 6. Presentation
Imagine that you have been asked to create a graph from the Dogs of NYC dataset that will be presented to a very important person (or people). The stakes are high.
(a) Who is the audience? (Mayor DeBlasio, a real estate developer, the voters, the City Council, the CEO of Purina...)
The general public is the intended audience of this graph; residents of New York City serve as a more niche audience.
(b) What is the main point you hope someone will take away from the graph?
The purpose of this Cleveland Dot Plot is to inform the public about popularities of dog `groups` within New York City over time. Specifically, the primary purpose of the graph is to display the significantly larger increase in popularity of `mutts` and `toy` dogs over time. From the graph, it is clear that the growth of these two `groups` greatly outpaces that of all other `groups`. All dog `groups` show increases in counts over time (as dogs in general become more popular as a pet), but beginning around 1996, the counts of `mutts` and `toy` dogs in NYC diverge from the counts of the other six dog `groups`.
(c) Present the graph, cleaned up to the standards of "presentation style." Pay attention to choice of graph type, if and how the data will be summarized, if and how the data will be subsetted, title, axis labels, axis breaks, axis tick mark labels, color, gridlines, and any other relevant features.
facet by borough
spayed/neutered color
```{r}
dog_groups_ts <- dogs_df_v1[c(2,4,5,12)] %>%
mutate(birth_year = substr(birth, 1, 4)) %>%
group_by(birth_year, Group) %>%
summarise(counts = n()) %>%
filter(1991 < birth_year & birth_year < 2012)
ggplot(dog_groups_ts, aes(x = counts,
y = birth_year,
color = Group)) +
geom_point() +
labs(color = 'Dog Group') +
ggtitle('NYC Dog Group Counts by Year') +
scale_x_continuous(name = 'Count') +
scale_y_discrete(name = 'Year') +
theme(axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
plot.title = element_text(hjust = 0.5, size = 16),
legend.title = element_text(hjust = 0.5, size = 10))
```
View(zips_df)
library(ggmap)
lonlat_sample <- as.numeric(geocode("the hollyood bowl"))
lonlat_sample  # note the order is longitude, latitiude
res <- revgeocode(lonlat_sample, output="more")
# can then access zip and neighborhood where populated
res$postal_code
res$neighborhood
library(zipcodes)
library(zipcode)
data(zipcode)
View(zipcode)
View(zipcode)
setwd("~/Desktop/projects/nyc_dogs")
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
library(ggplot)
library(dplyr)
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
# View missing data
df_na <- data.frame(lapply(df, function(x) {
gsub("n/a", NA, x)
}))
missing <- colSums(is.na(df_na))
missing_df <- data.frame(missing) %>%
add_rownames("var")
missing_df['missing_pct'] = (missing / nrow(dogs_df))*100
ggplot(filter(missing_df, missing_pct > 0), aes(x = reorder(var, -missing_pct), y = missing_pct)) +
geom_bar(stat = "identity",
fill = "red",
color = "black",
alpha = 0.6) +
ggtitle("Missing Values by Variable (excludes variables with no missing values)") +
scale_x_discrete(name = "Variable") +
scale_y_continuous(name = "Percent Missing") +
theme(plot.title = element_text(hjust = 0.5, size = 14),
axis.title.x = element_text(size = 12),
axis.title.y = element_text(size = 12))
library(tidyverse)
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
# View missing data
df_na <- data.frame(lapply(df, function(x) {
gsub("n/a", NA, x)
}))
missing <- colSums(is.na(df_na))
missing_df <- data.frame(missing) %>%
add_rownames("var")
missing_df['missing_pct'] = (missing / nrow(dogs_df))*100
ggplot(filter(missing_df, missing_pct > 0), aes(x = reorder(var, -missing_pct), y = missing_pct)) +
geom_bar(stat = "identity",
fill = "red",
color = "black",
alpha = 0.6) +
ggtitle("Missing Values by Variable (excludes variables with no missing values)") +
scale_x_discrete(name = "Variable") +
scale_y_continuous(name = "Percent Missing") +
theme(plot.title = element_text(hjust = 0.5, size = 14),
axis.title.x = element_text(size = 12),
axis.title.y = element_text(size = 12))
View(missing_df)
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
# View missing data
df_na <- data.frame(lapply(df, function(x) {
gsub("n/a", NA, x)
}))
View(df_na)
View(df)
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
# Clean NAs in dataset
df <- data.frame(lapply(df, function(x) {
gsub("n/a", NA, x)
}))
missing <- colSums(is.na(df))
missing_df <- data.frame(missing) %>%
add_rownames("var")
View(missing_df)
# Read in dataset
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
# Clean NAs
df <- data.frame(lapply(df, function(x) {
gsub("n/a", NA, x)
}))
# Get number of NAs in each column
missing <- colSums(is.na(df))
# Create dataframe from the above information, showing the percent of missing data in each column
missing_df <- data.frame(missing) %>%
add_rownames("var") %>%
mutate(missing_pct = missing / nrow(df)) * 100
df <- read.csv("./data/Dogs of NYC _ WNYC-filtered.csv")
# Clean NAs
df <- data.frame(lapply(df, function(x) {
gsub("n/a", NA, x)
}))
# Get number of NAs in each column
missing <- colSums(is.na(df))
# Create dataframe from the above information
missing_df <- data.frame(missing) %>%
add_rownames("var")
missing_df['missing_pct'] = (missing / nrow(dogs_df))*100
missing_df['missing_pct'] = (missing / nrow(df))*100
View(missing_df)
View(df)
